# NAMV-Dataset
A dedicated NICU action video dataset with fine-grained temporal annotations, designed for research on action recognition, temporal segmentation, and quality assessment in clinical scenarios.
# Download
The dataset can be fully downloaded through the following link [https://pan.quark.cn/s/2648409c2c8d]. It is completely open and shared, and no personal information is required for the download.
# Overview
The dataset focuses specifically on hand-based interactions during bedside care, designed to support clinically meaningful research in workflow recognition and procedural quality assessment. In accordance with established clinical protocols, seven high-frequency nursing procedures are systematically decomposed into 19 sub-actions, each annotated with frame-level temporal boundaries that span the preparation, execution, and completion phases. Data were acquired using an Orbbec Femto Bolt RGB-D sensor, which integrates an RGB camera, a depth camera, and active infrared illumination; corresponding per-frame 3D point clouds are also provided. Notably, this release includes RGB images, depth maps, infrared imagery, and 3D point clouds, but excludes pixel-aligned RGBâ€“depth images and skeleton trajectories. To the best of our knowledge, NAMV is the first multimodal dataset for NICU nursing workflows to integrate multiple sensing modalities with expert-annotated quality ratings at both the sub-action and event levels. This resource provides a robust foundation for advancing research in multimodal action recognition, temporal segmentation, and skill proficiency modeling under realistic clinical conditions, with potential applications in intelligent nursing assistance systems, clinical workflow analytics, and simulation-based training platforms.
